{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.10 python3.10-distutils python3.10-venv -y\n",
        "\n",
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "!update-alternatives --set python3 /usr/bin/python3.10\n",
        "\n",
        "# Install pip for Python 3.10\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python3 get-pip.py\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bf4fivsgIC4M",
        "outputId": "856a5a04-a045-4eb8-a0ec-0ffb366c22d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (108.138.128.112)] [\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r                                                                               \rGet:4 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,151 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,290 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,470 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,532 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,865 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,988 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,595 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,830 kB]\n",
            "Hit:19 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:20 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.8 kB]\n",
            "Fetched 31.2 MB in 2s (14.3 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.11).\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 2,481 kB of archives.\n",
            "After this operation, 2,754 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.7 [1,683 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.11 [5,726 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-setuptools-whl all 68.1.2-2~jammy3 [792 kB]\n",
            "Fetched 2,481 kB in 2s (1,127 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 121722 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.7_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-setuptools-whl (68.1.2-2~jammy3) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.11_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.11) ...\n",
            "Setting up python3-setuptools-whl (68.1.2-2~jammy3) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.11) ...\n",
            "update-alternatives: using /usr/bin/python3.10 to provide /usr/bin/python3 (python3) in manual mode\n",
            "--2025-11-21 01:57:48--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2182415 (2.1M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "get-pip.py          100%[===================>]   2.08M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-11-21 01:57:49 (33.2 MB/s) - ‘get-pip.py’ saved [2182415/2182415]\n",
            "\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pip]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pip-25.3 setuptools-80.9.0 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nc6HizakIUWZ",
        "outputId": "96e12e37-0be0-4c01-f796-076a5279eec9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_zJxG03hFky_",
        "outputId": "5b4efadc-4266-4a40-b16b-c45b086f32e0",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.1.2\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m  \u001b[33m0:00:26\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sympy (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.1.2) (2.0.1)\n",
            "INFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting networkx (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading https://download.pytorch.org/whl/fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Installing collected packages: mpmath, typing-extensions, sympy, networkx, jinja2, fsspec, filelock, triton, torch\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [torch]\n",
            "\u001b[1A\u001b[2KSuccessfully installed filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.3 sympy-1.14.0 torch-2.1.2+cu121 triton-2.1.0 typing-extensions-4.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.1.2 --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "J9aNmKvkIlaD",
        "outputId": "434cafd6-0bc3-46a9-81dc-ecc31972f19a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.0 (from -r requirements.txt (line 1))\n",
            "  Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Requirement already satisfied: torch==2.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.1.2+cu121)\n",
            "Collecting tokenizers==0.19.1 (from -r requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting transformers==4.40.0 (from -r requirements.txt (line 4))\n",
            "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
            "Collecting accelerate==0.29.3 (from -r requirements.txt (line 5))\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting nltk==3.8.1 (from -r requirements.txt (line 6))\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting tqdm==4.66.1 (from -r requirements.txt (line 7))\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting pytest==7.4.4 (from -r requirements.txt (line 8))\n",
            "  Downloading pytest-7.4.4-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting hypothesis==6.96.1 (from -r requirements.txt (line 9))\n",
            "  Downloading hypothesis-6.96.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting wandb==0.15.10 (from -r requirements.txt (line 10))\n",
            "  Downloading wandb-0.15.10-py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting matplotlib==3.8.0 (from -r requirements.txt (line 11))\n",
            "  Downloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting plotly==5.18.0 (from -r requirements.txt (line 12))\n",
            "  Downloading plotly-5.18.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting seaborn==0.13.2 (from -r requirements.txt (line 13))\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting bitsandbytes==0.43.1 (from -r requirements.txt (line 14))\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting sentencepiece==0.2.0 (from -r requirements.txt (line 15))\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 2)) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 2)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 2)) (2025.9.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 2)) (2.1.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers==0.19.1->-r requirements.txt (line 3))\n",
            "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting packaging>=20.0 (from transformers==4.40.0->-r requirements.txt (line 4))\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers==4.40.0->-r requirements.txt (line 4))\n",
            "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers==4.40.0->-r requirements.txt (line 4))\n",
            "  Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests (from transformers==4.40.0->-r requirements.txt (line 4))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers==4.40.0->-r requirements.txt (line 4))\n",
            "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting psutil (from accelerate==0.29.3->-r requirements.txt (line 5))\n",
            "  Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Collecting click (from nltk==3.8.1->-r requirements.txt (line 6))\n",
            "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting joblib (from nltk==3.8.1->-r requirements.txt (line 6))\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting iniconfig (from pytest==7.4.4->-r requirements.txt (line 8))\n",
            "  Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pluggy<2.0,>=0.12 (from pytest==7.4.4->-r requirements.txt (line 8))\n",
            "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting exceptiongroup>=1.0.0rc8 (from pytest==7.4.4->-r requirements.txt (line 8))\n",
            "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting tomli>=1.0.0 (from pytest==7.4.4->-r requirements.txt (line 8))\n",
            "  Downloading tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting attrs>=22.2.0 (from hypothesis==6.96.1->-r requirements.txt (line 9))\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis==6.96.1->-r requirements.txt (line 9))\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb==0.15.10->-r requirements.txt (line 10))\n",
            "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb==0.15.10->-r requirements.txt (line 10))\n",
            "  Downloading sentry_sdk-2.45.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb==0.15.10->-r requirements.txt (line 10))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pathtools (from wandb==0.15.10->-r requirements.txt (line 10))\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb==0.15.10->-r requirements.txt (line 10))\n",
            "  Downloading setproctitle-1.3.7-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.10->-r requirements.txt (line 10)) (80.9.0)\n",
            "Collecting appdirs>=1.4.3 (from wandb==0.15.10->-r requirements.txt (line 10))\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb==0.15.10->-r requirements.txt (line 10))\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib==3.8.0->-r requirements.txt (line 11))\n",
            "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib==3.8.0->-r requirements.txt (line 11))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib==3.8.0->-r requirements.txt (line 11))\n",
            "  Downloading fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib==3.8.0->-r requirements.txt (line 11))\n",
            "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pillow>=6.2.0 (from matplotlib==3.8.0->-r requirements.txt (line 11))\n",
            "  Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib==3.8.0->-r requirements.txt (line 11)) (2.4.7)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib==3.8.0->-r requirements.txt (line 11))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting tenacity>=6.2.0 (from plotly==5.18.0->-r requirements.txt (line 12))\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting pandas>=1.2 (from seaborn==0.13.2->-r requirements.txt (line 13))\n",
            "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1->-r requirements.txt (line 3))\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.40.0->-r requirements.txt (line 4))\n",
            "  Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers==4.40.0->-r requirements.txt (line 4))\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.40.0->-r requirements.txt (line 4))\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers==4.40.0->-r requirements.txt (line 4))\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb==0.15.10->-r requirements.txt (line 10)) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.10->-r requirements.txt (line 10))\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.10->-r requirements.txt (line 10))\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn==0.13.2->-r requirements.txt (line 13))\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=1.2->seaborn==0.13.2->-r requirements.txt (line 13))\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.1.2->-r requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->-r requirements.txt (line 2)) (1.3.0)\n",
            "Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "Downloading pytest-7.4.4-py3-none-any.whl (325 kB)\n",
            "Downloading hypothesis-6.96.1-py3-none-any.whl (435 kB)\n",
            "Downloading wandb-0.15.10-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-5.18.0-py3-none-any.whl (15.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
            "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
            "Downloading fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m138.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
            "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.3/770.3 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m791.7/791.7 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
            "Downloading sentry_sdk-2.45.0-py2.py3-none-any.whl (404 kB)\n",
            "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading tomli-2.3.0-py3-none-any.whl (14 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Downloading setproctitle-1.3.7-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (31 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8885 sha256=1d4b38ab01c9f10901e97d47802fcb3221d23a083d0947e7d7a832947c423451\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: sortedcontainers, sentencepiece, pytz, pathtools, appdirs, urllib3, tzdata, tqdm, tomli, tenacity, smmap, setproctitle, safetensors, regex, pyyaml, python-dateutil, psutil, protobuf, pluggy, pillow, packaging, numpy, kiwisolver, joblib, iniconfig, idna, hf-xet, fonttools, exceptiongroup, docker-pycreds, cycler, click, charset_normalizer, certifi, attrs, sentry-sdk, requests, pytest, plotly, pandas, nltk, hypothesis, gitdb, contourpy, matplotlib, huggingface-hub, GitPython, bitsandbytes, wandb, tokenizers, seaborn, accelerate, transformers\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53/53\u001b[0m [transformers]\n",
            "\u001b[1A\u001b[2KSuccessfully installed GitPython-3.1.45 accelerate-0.29.3 appdirs-1.4.4 attrs-25.4.0 bitsandbytes-0.43.1 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 contourpy-1.3.2 cycler-0.12.1 docker-pycreds-0.4.0 exceptiongroup-1.3.0 fonttools-4.60.1 gitdb-4.0.12 hf-xet-1.2.0 huggingface-hub-0.36.0 hypothesis-6.96.1 idna-3.11 iniconfig-2.3.0 joblib-1.5.2 kiwisolver-1.4.9 matplotlib-3.8.0 nltk-3.8.1 numpy-1.26.0 packaging-25.0 pandas-2.3.3 pathtools-0.1.2 pillow-12.0.0 plotly-5.18.0 pluggy-1.6.0 protobuf-4.25.8 psutil-7.1.3 pytest-7.4.4 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 seaborn-0.13.2 sentencepiece-0.2.0 sentry-sdk-2.45.0 setproctitle-1.3.7 smmap-5.0.2 sortedcontainers-2.4.0 tenacity-9.1.2 tokenizers-0.19.1 tomli-2.3.0 tqdm-4.66.1 transformers-4.40.0 tzdata-2025.2 urllib3-2.5.0 wandb-0.15.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python train_t5.py \\\n",
        "  --finetune \\\n",
        "  --learning_rate 3e-4 \\\n",
        "  --weight_decay 0.01 \\\n",
        "  --scheduler_type cosine \\\n",
        "  --num_warmup_epochs 1 \\\n",
        "  --max_n_epochs 20 \\\n",
        "  --patience_epochs 5 \\\n",
        "  --batch_size 16 \\\n",
        "  --test_batch_size 32 \\\n",
        "  --experiment_name ft_experiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vAXLwgaEGATa",
        "outputId": "8aa84727-f9d9-404b-d9cf-f590b8ef970b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 2.32kB [00:00, 11.4MB/s]\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 7.35MB/s]\n",
            "tokenizer.json: 1.39MB [00:00, 99.2MB/s]\n",
            "Loading pretrained T5-small for fine-tuning...\n",
            "config.json: 1.21kB [00:00, 7.38MB/s]\n",
            "model.safetensors: 100% 242M/242M [00:01<00:00, 184MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 1.23MB/s]\n",
            "Total parameters: 60,506,624\n",
            "Trainable parameters: 60,506,624\n",
            "100% 265/265 [00:42<00:00,  6.27it/s]\n",
            "Epoch 0: Average train loss was 2.5723379363468886\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:13<00:00,  4.87s/it]\n",
            "466it [00:01, 389.13it/s]\n",
            "Epoch 0: Dev loss: 0.35536925278057, Record F1: 0.12948366695526278, Record EM: 0.1223175965665236, SQL EM: 0.0\n",
            "Epoch 0: 87.12% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:41<00:00,  6.41it/s]\n",
            "Epoch 1: Average train loss was 0.32382499616959204\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:10<00:00,  4.70s/it]\n",
            "465it [02:00,  3.87it/s]\n",
            "Epoch 1: Dev loss: 0.1442330637296084, Record F1: 0.3405106704152227, Record EM: 0.27682403433476394, SQL EM: 0.002145922746781116\n",
            "Epoch 1: 47.00% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:42<00:00,  6.29it/s]\n",
            "Epoch 2: Average train loss was 0.17464024885087404\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [00:59<00:00,  3.97s/it]\n",
            "466it [01:02,  7.45it/s]\n",
            "Epoch 2: Dev loss: 0.09612399342403083, Record F1: 0.46464361829810413, Record EM: 0.37124463519313305, SQL EM: 0.006437768240343348\n",
            "Epoch 2: 31.12% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:42<00:00,  6.31it/s]\n",
            "Epoch 3: Average train loss was 0.12485269160540971\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:05<00:00,  4.36s/it]\n",
            "462it [02:00,  3.85it/s]\n",
            "Epoch 3: Dev loss: 0.07593680771581528, Record F1: 0.5235610416686844, Record EM: 0.43776824034334766, SQL EM: 0.015021459227467811\n",
            "Epoch 3: 26.82% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:42<00:00,  6.27it/s]\n",
            "Epoch 4: Average train loss was 0.09954120397257638\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:02<00:00,  4.18s/it]\n",
            "462it [02:00,  3.85it/s]\n",
            "Epoch 4: Dev loss: 0.06530235687184797, Record F1: 0.5363488362565695, Record EM: 0.44635193133047213, SQL EM: 0.017167381974248927\n",
            "Epoch 4: 27.04% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:43<00:00,  6.09it/s]\n",
            "Epoch 5: Average train loss was 0.08333658123090419\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:15<00:00,  5.01s/it]\n",
            "464it [02:00,  3.87it/s]\n",
            "Epoch 5: Dev loss: 0.056002251886675194, Record F1: 0.5741374052614823, Record EM: 0.4892703862660944, SQL EM: 0.017167381974248927\n",
            "Epoch 5: 21.67% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:43<00:00,  6.13it/s]\n",
            "Epoch 6: Average train loss was 0.071920658973579\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:15<00:00,  5.01s/it]\n",
            "464it [02:00,  3.87it/s]\n",
            "Epoch 6: Dev loss: 0.0495533899623959, Record F1: 0.649377983946835, Record EM: 0.5686695278969958, SQL EM: 0.017167381974248927\n",
            "Epoch 6: 17.17% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:42<00:00,  6.19it/s]\n",
            "Epoch 7: Average train loss was 0.06393759126832553\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:18<00:00,  5.24s/it]\n",
            "465it [02:00,  3.87it/s]\n",
            "Epoch 7: Dev loss: 0.043046654524504666, Record F1: 0.6797169888822707, Record EM: 0.6072961373390557, SQL EM: 0.019313304721030045\n",
            "Epoch 7: 15.02% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:43<00:00,  6.15it/s]\n",
            "Epoch 8: Average train loss was 0.05590676601956272\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:22<00:00,  5.53s/it]\n",
            "464it [02:00,  3.87it/s]\n",
            "Epoch 8: Dev loss: 0.03892267829778243, Record F1: 0.6868772446514996, Record EM: 0.6223175965665236, SQL EM: 0.017167381974248927\n",
            "Epoch 8: 14.38% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:43<00:00,  6.11it/s]\n",
            "Epoch 9: Average train loss was 0.050834661184108995\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:25<00:00,  5.70s/it]\n",
            "466it [00:44, 10.46it/s]\n",
            "Epoch 9: Dev loss: 0.0361719017878504, Record F1: 0.6883525690653904, Record EM: 0.628755364806867, SQL EM: 0.017167381974248927\n",
            "Epoch 9: 14.59% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:43<00:00,  6.07it/s]\n",
            "Epoch 10: Average train loss was 0.047244254636186166\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:22<00:00,  5.51s/it]\n",
            "462it [02:00,  3.85it/s]\n",
            "Epoch 10: Dev loss: 0.03376834919000204, Record F1: 0.7166871391107336, Record EM: 0.6609442060085837, SQL EM: 0.02145922746781116\n",
            "Epoch 10: 11.37% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:45<00:00,  5.84it/s]\n",
            "Epoch 11: Average train loss was 0.04282059783361675\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:39<00:00,  6.66s/it]\n",
            "461it [02:00,  3.84it/s]\n",
            "Epoch 11: Dev loss: 0.03189214374351519, Record F1: 0.7287350713205101, Record EM: 0.6738197424892703, SQL EM: 0.017167381974248927\n",
            "Epoch 11: 11.59% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:48<00:00,  5.42it/s]\n",
            "Epoch 12: Average train loss was 0.04011001136986567\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:01<00:00,  8.08s/it]\n",
            "463it [02:00,  3.86it/s]\n",
            "Epoch 12: Dev loss: 0.03065528248888978, Record F1: 0.7453284939854369, Record EM: 0.6952789699570815, SQL EM: 0.017167381974248927\n",
            "Epoch 12: 13.95% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:49<00:00,  5.38it/s]\n",
            "Epoch 13: Average train loss was 0.038309300981806696\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:58<00:00,  7.88s/it]\n",
            "462it [02:00,  3.85it/s]\n",
            "Epoch 13: Dev loss: 0.029173015534024474, Record F1: 0.7418967416093862, Record EM: 0.6952789699570815, SQL EM: 0.019313304721030045\n",
            "Epoch 13: 11.37% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:49<00:00,  5.34it/s]\n",
            "Epoch 14: Average train loss was 0.03633630924890397\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:19<00:00,  9.31s/it]\n",
            "464it [02:00,  3.87it/s]\n",
            "Epoch 14: Dev loss: 0.028560955585100856, Record F1: 0.749541671462619, Record EM: 0.7081545064377682, SQL EM: 0.019313304721030045\n",
            "Epoch 14: 11.80% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:50<00:00,  5.24it/s]\n",
            "Epoch 15: Average train loss was 0.03539246261343938\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:08<00:00,  8.54s/it]\n",
            "463it [02:00,  3.86it/s]\n",
            "Epoch 15: Dev loss: 0.028007282426374184, Record F1: 0.7524964581157223, Record EM: 0.7124463519313304, SQL EM: 0.019313304721030045\n",
            "Epoch 15: 11.80% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:52<00:00,  5.07it/s]\n",
            "Epoch 16: Average train loss was 0.03447951107465419\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:20<00:00,  9.33s/it]\n",
            "463it [02:00,  3.86it/s]\n",
            "Epoch 16: Dev loss: 0.02760615045078494, Record F1: 0.7583741821317288, Record EM: 0.7145922746781116, SQL EM: 0.019313304721030045\n",
            "Epoch 16: 11.16% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:53<00:00,  4.92it/s]\n",
            "Epoch 17: Average train loss was 0.03379399299630676\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:35<00:00, 10.37s/it]\n",
            "463it [02:00,  3.86it/s]\n",
            "Epoch 17: Dev loss: 0.027376223598250732, Record F1: 0.7561349584129645, Record EM: 0.7145922746781116, SQL EM: 0.019313304721030045\n",
            "Epoch 17: 13.09% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:54<00:00,  4.90it/s]\n",
            "Epoch 18: Average train loss was 0.033330769694927084\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:50<00:00, 11.38s/it]\n",
            "464it [02:00,  3.87it/s]\n",
            "Epoch 18: Dev loss: 0.027401270746676892, Record F1: 0.752151006202437, Record EM: 0.7103004291845494, SQL EM: 0.019313304721030045\n",
            "Epoch 18: 13.73% of the generated outputs led to SQL errors\n",
            "100% 265/265 [00:57<00:00,  4.62it/s]\n",
            "Epoch 19: Average train loss was 0.033026865156353565\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:47<00:00, 11.18s/it]\n",
            "464it [02:00,  3.87it/s]\n",
            "Epoch 19: Dev loss: 0.027410596913338234, Record F1: 0.7530093752942827, Record EM: 0.7103004291845494, SQL EM: 0.019313304721030045\n",
            "Epoch 19: 13.52% of the generated outputs led to SQL errors\n",
            "Loading model from checkpoints/ft_experiments/ft_experiment/best_model\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:51<00:00, 11.40s/it]\n",
            "463it [02:00,  3.86it/s]\n",
            "Dev set results: Loss: {dev_loss}, Record F1: {dev_record_f1}, Record EM: {dev_record_em}, SQL EM: {dev_sql_em}\n",
            "Dev set results: 11.16% of the generated outputs led to SQL errors\n",
            "Test Inference: 100% 14/14 [05:03<00:00, 21.67s/it]\n",
            "Generated 432 test queries\n",
            "431it [02:00,  3.59it/s]\n",
            "Test results saved to results/t5_ft_ft_experiment_test.sql and records/t5_ft_ft_experiment_test.pkl\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5TokenizerFast\n",
        "import os\n",
        "\n",
        "def compute_stats(split):\n",
        "    tokenizer = T5TokenizerFast.from_pretrained('google-t5/t5-small')\n",
        "\n",
        "    nl_path = f'data/{split}.nl'\n",
        "    sql_path = f'data/{split}.sql'\n",
        "\n",
        "    with open(nl_path, 'r') as f:\n",
        "        nl_queries = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    with open(sql_path, 'r') as f:\n",
        "        sql_queries = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    nl_tokens = [tokenizer.tokenize(q) for q in nl_queries]\n",
        "    sql_tokens = [tokenizer.tokenize(q) for q in sql_queries]\n",
        "\n",
        "    num_examples = len(nl_queries)\n",
        "    mean_nl_len = sum(len(t) for t in nl_tokens) / len(nl_tokens)\n",
        "    mean_sql_len = sum(len(t) for t in sql_tokens) / len(sql_tokens)\n",
        "\n",
        "    nl_vocab = set()\n",
        "    for tokens in nl_tokens:\n",
        "        nl_vocab.update(tokens)\n",
        "\n",
        "    sql_vocab = set()\n",
        "    for tokens in sql_tokens:\n",
        "        sql_vocab.update(tokens)\n",
        "\n",
        "    print(f\"\\n{split.upper()} Statistics:\")\n",
        "    print(f\"Number of examples: {num_examples}\")\n",
        "    print(f\"Mean NL length: {mean_nl_len:.2f}\")\n",
        "    print(f\"Mean SQL length: {mean_sql_len:.2f}\")\n",
        "    print(f\"NL vocab size: {len(nl_vocab)}\")\n",
        "    print(f\"SQL vocab size: {len(sql_vocab)}\")\n",
        "\n",
        "    return num_examples, mean_nl_len, mean_sql_len, len(nl_vocab), len(sql_vocab)\n",
        "\n",
        "train_stats = compute_stats('train')\n",
        "dev_stats = compute_stats('dev')"
      ],
      "metadata": {
        "id": "gqOkgx6mGZKd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6bedfd3c-e44d-4e87-fc3e-94e386082a5c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRAIN Statistics:\n",
            "Number of examples: 4225\n",
            "Mean NL length: 17.10\n",
            "Mean SQL length: 216.37\n",
            "NL vocab size: 791\n",
            "SQL vocab size: 555\n",
            "\n",
            "DEV Statistics:\n",
            "Number of examples: 466\n",
            "Mean NL length: 17.07\n",
            "Mean SQL length: 210.05\n",
            "NL vocab size: 465\n",
            "SQL vocab size: 395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from train_t5 import eval_epoch, load_model_from_checkpoint\n",
        "from load_data import load_t5_data\n",
        "import argparse\n",
        "\n",
        "class Args:\n",
        "    checkpoint_dir = 'checkpoints/ft_experiments/ft_experiment'\n",
        "    finetune = True\n",
        "\n",
        "args = Args()\n",
        "\n",
        "model = load_model_from_checkpoint(args, best=True)\n",
        "\n",
        "_, dev_loader, _ = load_t5_data(batch_size=16, test_batch_size=32)\n",
        "\n",
        "eval_loss, record_f1, record_em, sql_em, error_rate = eval_epoch(\n",
        "    args, model, dev_loader,\n",
        "    gt_sql_pth='data/dev.sql',\n",
        "    model_sql_path='results/t5_ft_ft_experiment_dev.sql',\n",
        "    gt_record_path='records/ground_truth_dev.pkl',\n",
        "    model_record_path='records/t5_ft_ft_experiment_dev.pkl'\n",
        ")\n",
        "\n",
        "print(f\"Dev F1: {record_f1:.4f}\")\n",
        "print(f\"Dev Record EM: {record_em:.4f}\")\n",
        "print(f\"Dev SQL EM: {sql_em:.4f}\")\n",
        "print(f\"Error Rate: {error_rate*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oFRuK5iMhW4X",
        "outputId": "f21c9753-17e6-41b1-de2b-67de1ec03293"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from checkpoints/ft_experiments/ft_experiment/best_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:   0%|          | 0/15 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating: 100%|██████████| 15/15 [01:08<00:00,  4.57s/it]\n",
            "463it [02:00,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev F1: 0.7584\n",
            "Dev Record EM: 0.7146\n",
            "Dev SQL EM: 0.0193\n",
            "Error Rate: 11.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Error Analysis Script for Q6\n",
        "Analyzes model predictions to identify and categorize errors\n",
        "\"\"\"\n",
        "\n",
        "import pickle\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "def load_data(nl_path, gt_sql_path, pred_sql_path, gt_record_path, pred_record_path):\n",
        "    \"\"\"Load all necessary data for error analysis\"\"\"\n",
        "\n",
        "    with open(nl_path, 'r') as f:\n",
        "        nl_queries = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    with open(gt_sql_path, 'r') as f:\n",
        "        gt_sql = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    with open(pred_sql_path, 'r') as f:\n",
        "        pred_sql = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    with open(gt_record_path, 'rb') as f:\n",
        "        gt_records, _ = pickle.load(f)\n",
        "\n",
        "    with open(pred_record_path, 'rb') as f:\n",
        "        pred_records, error_msgs = pickle.load(f)\n",
        "\n",
        "    return nl_queries, gt_sql, pred_sql, gt_records, pred_records, error_msgs\n",
        "\n",
        "\n",
        "def categorize_error(nl, gt, pred, gt_rec, pred_rec, error_msg):\n",
        "    \"\"\"\n",
        "    Categorize a single error into predefined types\n",
        "    Returns: error_type (str) or None if no error\n",
        "    \"\"\"\n",
        "\n",
        "    if gt.lower() == pred.lower():\n",
        "        return None\n",
        "    if set(gt_rec) == set(pred_rec) and error_msg == \"\":\n",
        "        return None\n",
        "\n",
        "    if error_msg != \"\":\n",
        "        return \"syntax_error\"\n",
        "\n",
        "    gt_tables = set(re.findall(r'FROM\\s+(\\w+)', gt, re.IGNORECASE))\n",
        "    pred_tables = set(re.findall(r'FROM\\s+(\\w+)', pred, re.IGNORECASE))\n",
        "\n",
        "    if gt_tables != pred_tables:\n",
        "        return \"table_name_error\"\n",
        "\n",
        "    gt_has_join = 'JOIN' in gt.upper()\n",
        "    pred_has_join = 'JOIN' in pred.upper()\n",
        "\n",
        "    if gt_has_join and not pred_has_join:\n",
        "        return \"missing_join\"\n",
        "\n",
        "    gt_where = re.search(r'WHERE\\s+(.+?)(?:ORDER|GROUP|LIMIT|$)', gt, re.IGNORECASE)\n",
        "    pred_where = re.search(r'WHERE\\s+(.+?)(?:ORDER|GROUP|LIMIT|$)', pred, re.IGNORECASE)\n",
        "\n",
        "    if gt_where and pred_where:\n",
        "        gt_where_clause = gt_where.group(1).strip()\n",
        "        pred_where_clause = pred_where.group(1).strip()\n",
        "\n",
        "        if gt_where_clause.replace(' ', '') != pred_where_clause.replace(' ', ''):\n",
        "            if any(op in gt_where_clause for op in ['<', '>', '<=', '>=', '!=']) or \\\n",
        "               any(op in pred_where_clause for op in ['<', '>', '<=', '>=', '!=']):\n",
        "                return \"wrong_operator\"\n",
        "            return \"wrong_where_condition\"\n",
        "\n",
        "    if gt_where and not pred_where:\n",
        "        return \"missing_where\"\n",
        "\n",
        "    gt_select = re.search(r'SELECT\\s+(.+?)\\s+FROM', gt, re.IGNORECASE)\n",
        "    pred_select = re.search(r'SELECT\\s+(.+?)\\s+FROM', pred, re.IGNORECASE)\n",
        "\n",
        "    if gt_select and pred_select:\n",
        "        if gt_select.group(1).strip() != pred_select.group(1).strip():\n",
        "            return \"wrong_columns\"\n",
        "\n",
        "    gt_order = 'ORDER BY' in gt.upper()\n",
        "    pred_order = 'ORDER BY' in pred.upper()\n",
        "\n",
        "    if gt_order != pred_order:\n",
        "        return \"wrong_ordering\"\n",
        "\n",
        "    return \"other_error\"\n",
        "\n",
        "\n",
        "def analyze_errors(nl_queries, gt_sql, pred_sql, gt_records, pred_records, error_msgs):\n",
        "    \"\"\"Analyze all errors and categorize them\"\"\"\n",
        "\n",
        "    error_counts = defaultdict(int)\n",
        "    error_examples = defaultdict(list)\n",
        "\n",
        "    total_queries = len(nl_queries)\n",
        "\n",
        "    for i, (nl, gt, pred, gt_rec, pred_rec, err_msg) in enumerate(\n",
        "        zip(nl_queries, gt_sql, pred_sql, gt_records, pred_records, error_msgs)\n",
        "    ):\n",
        "        error_type = categorize_error(nl, gt, pred, gt_rec, pred_rec, err_msg)\n",
        "\n",
        "        if error_type:\n",
        "            error_counts[error_type] += 1\n",
        "\n",
        "            if len(error_examples[error_type]) < 5:\n",
        "                error_examples[error_type].append({\n",
        "                    'nl': nl,\n",
        "                    'gt': gt,\n",
        "                    'pred': pred,\n",
        "                    'index': i\n",
        "                })\n",
        "\n",
        "    return error_counts, error_examples, total_queries\n",
        "\n",
        "\n",
        "def print_error_analysis(error_counts, error_examples, total_queries):\n",
        "    \"\"\"Print formatted error analysis\"\"\"\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"ERROR ANALYSIS SUMMARY\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nTotal queries analyzed: {total_queries}\")\n",
        "    print(f\"Queries with errors: {sum(error_counts.values())}\")\n",
        "    print(f\"Queries correct: {total_queries - sum(error_counts.values())}\")\n",
        "    print(f\"\\nAccuracy: {(total_queries - sum(error_counts.values())) / total_queries * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ERROR TYPE BREAKDOWN\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    sorted_errors = sorted(error_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    for error_type, count in sorted_errors:\n",
        "        print(f\"\\n{error_type.upper().replace('_', ' ')}: {count}/{total_queries} ({count/total_queries*100:.1f}%)\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        examples = error_examples[error_type]\n",
        "        for j, ex in enumerate(examples[:3], 1):\n",
        "            print(f\"\\nExample {j} (Index {ex['index']}):\")\n",
        "            print(f\"  NL Query: {ex['nl'][:100]}...\")\n",
        "            print(f\"  Ground Truth: {ex['gt'][:100]}...\")\n",
        "            print(f\"  Predicted:    {ex['pred'][:100]}...\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TOP 3 ERROR TYPES FOR TABLE 5:\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for i, (error_type, count) in enumerate(sorted_errors[:3], 1):\n",
        "        print(f\"\\n{i}. {error_type.replace('_', ' ').title()}\")\n",
        "        print(f\"   Statistics: {count}/{total_queries}\")\n",
        "\n",
        "        if error_examples[error_type]:\n",
        "            ex = error_examples[error_type][0]\n",
        "            print(f\"   Example NL: {ex['nl'][:80]}...\")\n",
        "            print(f\"   Generated: {ex['pred'][:80]}...\")\n",
        "            print(f\"   Ground Truth: {ex['gt'][:80]}...\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    nl_path = 'data/dev.nl'\n",
        "    gt_sql_path = 'data/dev.sql'\n",
        "    pred_sql_path = 'results/t5_ft_ft_experiment_dev.sql'\n",
        "    gt_record_path = 'records/ground_truth_dev.pkl'\n",
        "    pred_record_path = 'records/t5_ft_ft_experiment_dev.pkl'\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    nl_queries, gt_sql, pred_sql, gt_records, pred_records, error_msgs = load_data(\n",
        "        nl_path, gt_sql_path, pred_sql_path, gt_record_path, pred_record_path\n",
        "    )\n",
        "\n",
        "    print(\"Analyzing errors...\")\n",
        "    error_counts, error_examples, total_queries = analyze_errors(\n",
        "        nl_queries, gt_sql, pred_sql, gt_records, pred_records, error_msgs\n",
        "    )\n",
        "\n",
        "    print_error_analysis(error_counts, error_examples, total_queries)\n",
        "\n",
        "    with open('error_analysis_detailed.txt', 'w') as f:\n",
        "        f.write(\"DETAILED ERROR LOG\\n\")\n",
        "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
        "\n",
        "        for error_type, examples in error_examples.items():\n",
        "            f.write(f\"\\n{error_type.upper()}\\n\")\n",
        "            f.write(\"-\" * 80 + \"\\n\")\n",
        "\n",
        "            for ex in examples:\n",
        "                f.write(f\"\\nIndex: {ex['index']}\\n\")\n",
        "                f.write(f\"NL: {ex['nl']}\\n\")\n",
        "                f.write(f\"GT: {ex['gt']}\\n\")\n",
        "                f.write(f\"Pred: {ex['pred']}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "    print(\"\\n Detailed error log saved to: error_analysis_detailed.txt\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1NFfn2ujirLK",
        "outputId": "8daad157-8a2c-48e6-f2cb-152f10e705f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Analyzing errors...\n",
            "================================================================================\n",
            "ERROR ANALYSIS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Total queries analyzed: 466\n",
            "Queries with errors: 138\n",
            "Queries correct: 328\n",
            "\n",
            "Accuracy: 70.39%\n",
            "\n",
            "================================================================================\n",
            "ERROR TYPE BREAKDOWN\n",
            "================================================================================\n",
            "\n",
            "SYNTAX ERROR: 52/466 (11.2%)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 1 (Index 2):\n",
            "  NL Query: list all arrivals from any airport to baltimore on thursday morning arriving before 9am...\n",
            "  Ground Truth: SELECT state_1.state_code FROM state state_1 WHERE state_1.state_code = 'ASD';...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport_service_1, city cit...\n",
            "\n",
            "Example 2 (Index 18):\n",
            "  NL Query: what's the lowest round trip fare from dallas to any city...\n",
            "  Ground Truth: SELECT DISTINCT fare_1.fare_id FROM fare fare_1 , flight_fare flight_fare_1 , flight flight_1 , airp...\n",
            "  Predicted:    SELECT DISTINCT fare_1.fare_id FROM fare fare_1, flight_fare flight_fare_1, flight flight_1, airport...\n",
            "\n",
            "Example 3 (Index 23):\n",
            "  NL Query: what are the flights and prices from la to charlotte for monday morning...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , flight_fare flight_fare_1 , fare fare_1 , ...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, flight_fare flight_fare_1, fare fare_1, air...\n",
            "\n",
            "WRONG WHERE CONDITION: 48/466 (10.3%)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 1 (Index 5):\n",
            "  NL Query: i'm starting from denver...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , airport_service airport_service_1 , city c...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport_service_1, city cit...\n",
            "\n",
            "Example 2 (Index 20):\n",
            "  NL Query: list all flights from boston to san francisco with the maximum number of stops...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , airport_service airport_service_1 , city c...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport_service_1, city cit...\n",
            "\n",
            "Example 3 (Index 30):\n",
            "  NL Query: i want an early morning flight between philadelphia and pittsburgh on tuesday morning...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , airport_service airport_service_1 , city c...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport_service_1, city cit...\n",
            "\n",
            "TABLE NAME ERROR: 15/466 (3.2%)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 1 (Index 71):\n",
            "  NL Query: what does iah mean...\n",
            "  Ground Truth: SELECT DISTINCT airport_1.airport_code FROM airport airport_1 WHERE airport_1.airport_code = 'IAH'...\n",
            "  Predicted:    SELECT DISTINCT airline_1.airline_code FROM airline airline_1 WHERE airline_1.airline_code = 'IAH'...\n",
            "\n",
            "Example 2 (Index 100):\n",
            "  NL Query: train to newark...\n",
            "  Ground Truth: SELECT DISTINCT ground_service_1.transport_type FROM ground_service ground_service_1 , city city_1 W...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport_service_1, city cit...\n",
            "\n",
            "Example 3 (Index 101):\n",
            "  NL Query: i'm traveling from boston to atlanta and i'd like to go sometime after 5pm but i want to know what k...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , equipment_sequence equipment_sequence_1 , ...\n",
            "  Predicted:    SELECT DISTINCT aircraft_1.aircraft_code FROM aircraft aircraft_1, equipment_sequence equipment_sequ...\n",
            "\n",
            "WRONG OPERATOR: 13/466 (2.8%)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 1 (Index 22):\n",
            "  NL Query: show me the flights arriving in baltimore from philadelphia at about 4 o'clock...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , airport_service airport_service_1 , city c...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport_service_1, city cit...\n",
            "\n",
            "Example 2 (Index 25):\n",
            "  NL Query: what are the flights available between 10am and 3pm between pittsburgh and fort worth...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , airport_service airport_service_1 , city c...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport_service_1, city cit...\n",
            "\n",
            "Example 3 (Index 36):\n",
            "  NL Query: i need an early flight from dallas to houston...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , airport_service airport_service_1 , city c...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport_service_1, city cit...\n",
            "\n",
            "OTHER ERROR: 6/466 (1.3%)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 1 (Index 32):\n",
            "  NL Query: now i'd like flights from philadelphia to pittsburgh leaving between 430 and 530pm...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , airport_service airport_service_1 , city c...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport_service_1, city cit...\n",
            "\n",
            "Example 2 (Index 79):\n",
            "  NL Query: flights from la guardia or jfk to cleveland...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , airport airport_1 , airport airport_2 , ai...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport airport_1, airport airport_2 WHERE ...\n",
            "\n",
            "Example 3 (Index 150):\n",
            "  NL Query: show me the list of flights from dallas to baltimore on american and delta airlines...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , airport_service airport_service_1 , city c...\n",
            "  Predicted:    SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport_service_1, city cit...\n",
            "\n",
            "WRONG COLUMNS: 4/466 (0.9%)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 1 (Index 117):\n",
            "  NL Query: show me about the ground transportation in boston...\n",
            "  Ground Truth: SELECT DISTINCT ground_service_1.transport_type , ground_service_1.ground_fare FROM ground_service g...\n",
            "  Predicted:    SELECT DISTINCT ground_service_1.transport_type FROM ground_service ground_service_1, city city_1 WH...\n",
            "\n",
            "Example 2 (Index 306):\n",
            "  NL Query: define airline us...\n",
            "  Ground Truth: SELECT DISTINCT airline_1.airline_code , airline_1.airline_name , airline_1.note FROM airline airlin...\n",
            "  Predicted:    SELECT DISTINCT airline_1.airline_code FROM airline airline_1 WHERE airline_1.airline_code = 'US'...\n",
            "\n",
            "Example 3 (Index 361):\n",
            "  NL Query: how long does it take to get from kansas city to st. paul...\n",
            "  Ground Truth: SELECT DISTINCT flight_1.time_elapsed FROM flight flight_1 , airport_service airport_service_1 , cit...\n",
            "  Predicted:    SELECT DISTINCT flight_1.departure_time FROM flight flight_1, airport_service airport_service_1, cit...\n",
            "\n",
            "================================================================================\n",
            "TOP 3 ERROR TYPES FOR TABLE 5:\n",
            "================================================================================\n",
            "\n",
            "1. Syntax Error\n",
            "   Statistics: 52/466\n",
            "   Example NL: list all arrivals from any airport to baltimore on thursday morning arriving bef...\n",
            "   Generated: SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport...\n",
            "   Ground Truth: SELECT state_1.state_code FROM state state_1 WHERE state_1.state_code = 'ASD';...\n",
            "\n",
            "2. Wrong Where Condition\n",
            "   Statistics: 48/466\n",
            "   Example NL: i'm starting from denver...\n",
            "   Generated: SELECT DISTINCT flight_1.flight_id FROM flight flight_1, airport_service airport...\n",
            "   Ground Truth: SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , airport_service airpor...\n",
            "\n",
            "3. Table Name Error\n",
            "   Statistics: 15/466\n",
            "   Example NL: what does iah mean...\n",
            "   Generated: SELECT DISTINCT airline_1.airline_code FROM airline airline_1 WHERE airline_1.ai...\n",
            "   Ground Truth: SELECT DISTINCT airport_1.airport_code FROM airport airport_1 WHERE airport_1.ai...\n",
            "\n",
            " Detailed error log saved to: error_analysis_detailed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python train_t5.py \\\n",
        "  --learning_rate 1e-4 \\\n",
        "  --weight_decay 0.01 \\\n",
        "  --scheduler_type linear \\\n",
        "  --num_warmup_epochs 5 \\\n",
        "  --max_n_epochs 100 \\\n",
        "  --patience_epochs 20 \\\n",
        "  --batch_size 32 \\\n",
        "  --test_batch_size 32 \\\n",
        "  --experiment_name scr_low_lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bJ8M-GNGiw5I",
        "outputId": "a1355a6f-1124-4729-f6c2-e13777f43cc4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Initializing T5-small from scratch...\n",
            "Total parameters: 60,506,624\n",
            "Trainable parameters: 60,506,624\n",
            "100% 133/133 [00:42<00:00,  3.12it/s]\n",
            "Epoch 0: Average train loss was 6.894189240737636\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:15<00:00,  5.01s/it]\n",
            "466it [00:00, 8513.20it/s]\n",
            "Epoch 0: Dev loss: 3.09763571317422, Record F1: 0.11802575048283262, Record EM: 0.11802575107296137, SQL EM: 0.0\n",
            "Epoch 0: 0.00% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:41<00:00,  3.19it/s]\n",
            "Epoch 1: Average train loss was 2.2730495863083275\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:17<00:00,  5.16s/it]\n",
            "466it [00:00, 1225.07it/s]\n",
            "Epoch 1: Dev loss: 1.397821778569958, Record F1: 0.11802575048283262, Record EM: 0.11802575107296137, SQL EM: 0.0\n",
            "Epoch 1: 100.00% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:41<00:00,  3.19it/s]\n",
            "Epoch 2: Average train loss was 1.2820163503302349\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:16<00:00,  5.13s/it]\n",
            "466it [00:00, 858.65it/s]\n",
            "Epoch 2: Dev loss: 0.9699875910042556, Record F1: 0.11802575048283262, Record EM: 0.11802575107296137, SQL EM: 0.0\n",
            "Epoch 2: 100.00% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:41<00:00,  3.17it/s]\n",
            "Epoch 3: Average train loss was 0.8797699222463852\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [00:55<00:00,  3.69s/it]\n",
            "466it [00:00, 834.76it/s]\n",
            "Epoch 3: Dev loss: 0.708690255156441, Record F1: 0.11802575048283262, Record EM: 0.11802575107296137, SQL EM: 0.0\n",
            "Epoch 3: 100.00% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:41<00:00,  3.19it/s]\n",
            "Epoch 4: Average train loss was 0.6402308425552685\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [00:27<00:00,  1.83s/it]\n",
            "466it [00:01, 236.02it/s]\n",
            "Epoch 4: Dev loss: 0.4846201164203842, Record F1: 0.11587982774678111, Record EM: 0.11587982832618025, SQL EM: 0.0\n",
            "Epoch 4: 85.41% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:41<00:00,  3.18it/s]\n",
            "Epoch 5: Average train loss was 0.48722893969027103\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [00:54<00:00,  3.62s/it]\n",
            "466it [00:00, 466.21it/s]\n",
            "Epoch 5: Dev loss: 0.3707763488413345, Record F1: 0.13028816611478497, Record EM: 0.12660944206008584, SQL EM: 0.0\n",
            "Epoch 5: 94.21% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:42<00:00,  3.15it/s]\n",
            "Epoch 6: Average train loss was 0.3889879172618575\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [00:38<00:00,  2.57s/it]\n",
            "466it [00:05, 87.69it/s]\n",
            "Epoch 6: Dev loss: 0.2887299382937879, Record F1: 0.1406737120469493, Record EM: 0.13090128755364808, SQL EM: 0.0\n",
            "Epoch 6: 49.79% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:41<00:00,  3.18it/s]\n",
            "Epoch 7: Average train loss was 0.3188357382824917\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:16<00:00,  5.09s/it]\n",
            "466it [00:07, 61.83it/s]\n",
            "Epoch 7: Dev loss: 0.23789783392718816, Record F1: 0.1336751741310518, Record EM: 0.12017167381974249, SQL EM: 0.0\n",
            "Epoch 7: 33.69% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:41<00:00,  3.17it/s]\n",
            "Epoch 8: Average train loss was 0.27467264936345287\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:15<00:00,  5.01s/it]\n",
            "466it [00:05, 81.75it/s]\n",
            "Epoch 8: Dev loss: 0.21664818321327312, Record F1: 0.13576119031014827, Record EM: 0.12017167381974249, SQL EM: 0.0\n",
            "Epoch 8: 44.85% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:41<00:00,  3.19it/s]\n",
            "Epoch 9: Average train loss was 0.24475434491227582\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [00:51<00:00,  3.40s/it]\n",
            "466it [00:07, 58.77it/s]\n",
            "Epoch 9: Dev loss: 0.19175733319565882, Record F1: 0.1307741200342556, Record EM: 0.1072961373390558, SQL EM: 0.0\n",
            "Epoch 9: 31.12% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:41<00:00,  3.19it/s]\n",
            "Epoch 10: Average train loss was 0.21055718505856874\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:06<00:00,  4.43s/it]\n",
            "464it [02:00,  3.87it/s]\n",
            "Epoch 10: Dev loss: 0.15476957693893137, Record F1: 0.171561799383957, Record EM: 0.15236051502145923, SQL EM: 0.002145922746781116\n",
            "Epoch 10: 21.24% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:41<00:00,  3.19it/s]\n",
            "Epoch 11: Average train loss was 0.18658306017516763\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:01<00:00,  4.11s/it]\n",
            "466it [00:14, 31.97it/s]\n",
            "Epoch 11: Dev loss: 0.15664014819732547, Record F1: 0.14261189381661996, Record EM: 0.1351931330472103, SQL EM: 0.002145922746781116\n",
            "Epoch 11: 92.92% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:42<00:00,  3.16it/s]\n",
            "Epoch 12: Average train loss was 0.16808822245183191\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:02<00:00,  4.16s/it]\n",
            "461it [02:00,  3.84it/s]\n",
            "Epoch 12: Dev loss: 0.12737855580176718, Record F1: 0.24270225611110927, Record EM: 0.19742489270386265, SQL EM: 0.002145922746781116\n",
            "Epoch 12: 24.68% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:42<00:00,  3.10it/s]\n",
            "Epoch 13: Average train loss was 0.15131250872293062\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:15<00:00,  5.06s/it]\n",
            "466it [00:30, 15.15it/s]\n",
            "Epoch 13: Dev loss: 0.12885270956163758, Record F1: 0.2505401396129616, Record EM: 0.23390557939914164, SQL EM: 0.002145922746781116\n",
            "Epoch 13: 61.37% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:42<00:00,  3.11it/s]\n",
            "Epoch 14: Average train loss was 0.14237973488901787\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:24<00:00,  5.61s/it]\n",
            "465it [02:00,  3.87it/s]\n",
            "Epoch 14: Dev loss: 0.106415201596489, Record F1: 0.2549056303439727, Record EM: 0.2145922746781116, SQL EM: 0.002145922746781116\n",
            "Epoch 14: 20.17% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:42<00:00,  3.11it/s]\n",
            "Epoch 15: Average train loss was 0.12585689938923364\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:25<00:00,  5.72s/it]\n",
            "460it [02:00,  3.83it/s]\n",
            "Epoch 15: Dev loss: 0.12801093064523023, Record F1: 0.11252730913504311, Record EM: 0.10300429184549356, SQL EM: 0.0\n",
            "Epoch 15: 37.34% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:44<00:00,  2.97it/s]\n",
            "Epoch 16: Average train loss was 0.12776047026232337\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:50<00:00,  7.35s/it]\n",
            "466it [00:53,  8.77it/s]\n",
            "Epoch 16: Dev loss: 0.09189833479982558, Record F1: 0.2718778101699015, Record EM: 0.23390557939914164, SQL EM: 0.002145922746781116\n",
            "Epoch 16: 21.46% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:44<00:00,  2.97it/s]\n",
            "Epoch 17: Average train loss was 0.10864529401542171\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:46<00:00,  7.12s/it]\n",
            "464it [02:00,  3.87it/s]\n",
            "Epoch 17: Dev loss: 0.08180199035536326, Record F1: 0.33712884115139297, Record EM: 0.30042918454935624, SQL EM: 0.002145922746781116\n",
            "Epoch 17: 14.59% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:44<00:00,  2.97it/s]\n",
            "Epoch 18: Average train loss was 0.09999479253424177\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:02<00:00,  8.16s/it]\n",
            "466it [01:08,  6.76it/s]\n",
            "Epoch 18: Dev loss: 0.07701654953981167, Record F1: 0.35720931832943126, Record EM: 0.315450643776824, SQL EM: 0.002145922746781116\n",
            "Epoch 18: 16.74% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:45<00:00,  2.95it/s]\n",
            "Epoch 19: Average train loss was 0.09024567207572663\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:55<00:00,  7.67s/it]\n",
            "464it [02:00,  3.87it/s]\n",
            "Epoch 19: Dev loss: 0.07095991034305443, Record F1: 0.3705726444045462, Record EM: 0.3369098712446352, SQL EM: 0.004291845493562232\n",
            "Epoch 19: 17.60% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:45<00:00,  2.94it/s]\n",
            "Epoch 20: Average train loss was 0.08419970874532734\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [01:56<00:00,  7.79s/it]\n",
            "466it [01:15,  6.14it/s]\n",
            "Epoch 20: Dev loss: 0.06594820686608968, Record F1: 0.36913473533548535, Record EM: 0.3240343347639485, SQL EM: 0.006437768240343348\n",
            "Epoch 20: 13.09% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:44<00:00,  2.97it/s]\n",
            "Epoch 21: Average train loss was 0.0780862377147842\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:03<00:00,  8.25s/it]\n",
            "464it [02:00,  3.87it/s]\n",
            "Epoch 21: Dev loss: 0.0639741591344608, Record F1: 0.3804911993949733, Record EM: 0.3497854077253219, SQL EM: 0.006437768240343348\n",
            "Epoch 21: 12.88% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:45<00:00,  2.94it/s]\n",
            "Epoch 22: Average train loss was 0.0729210841410832\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:07<00:00,  8.47s/it]\n",
            "466it [00:00, 797.27it/s]\n",
            "Epoch 22: Dev loss: 0.1828582519113201, Record F1: 0.12017167321888411, Record EM: 0.12017167381974249, SQL EM: 0.006437768240343348\n",
            "Epoch 22: 97.00% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:45<00:00,  2.89it/s]\n",
            "Epoch 23: Average train loss was 0.0912010631645714\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:18<00:00,  9.24s/it]\n",
            "466it [01:06,  6.98it/s]\n",
            "Epoch 23: Dev loss: 0.05955092822463104, Record F1: 0.39943950498537106, Record EM: 0.37124463519313305, SQL EM: 0.006437768240343348\n",
            "Epoch 23: 18.03% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:45<00:00,  2.93it/s]\n",
            "Epoch 24: Average train loss was 0.06745673649992563\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:20<00:00,  9.34s/it]\n",
            "466it [00:40, 11.51it/s]\n",
            "Epoch 24: Dev loss: 0.09223739360609949, Record F1: 0.29759401437358, Record EM: 0.28969957081545067, SQL EM: 0.008583690987124463\n",
            "Epoch 24: 62.45% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:44<00:00,  2.99it/s]\n",
            "Epoch 25: Average train loss was 0.07706679370258299\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:06<00:00,  8.46s/it]\n",
            "465it [02:00,  3.87it/s]\n",
            "Epoch 25: Dev loss: 0.05502709643733578, Record F1: 0.4398190919654789, Record EM: 0.3969957081545064, SQL EM: 0.008583690987124463\n",
            "Epoch 25: 13.09% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:45<00:00,  2.93it/s]\n",
            "Epoch 26: Average train loss was 0.05898113439086614\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:07<00:00,  8.47s/it]\n",
            "463it [02:00,  3.86it/s]\n",
            "Epoch 26: Dev loss: 0.05173334334431583, Record F1: 0.45709463159388436, Record EM: 0.4334763948497854, SQL EM: 0.006437768240343348\n",
            "Epoch 26: 10.30% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:46<00:00,  2.86it/s]\n",
            "Epoch 27: Average train loss was 0.05503086216741506\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:23<00:00,  9.59s/it]\n",
            "461it [02:00,  3.84it/s]\n",
            "Epoch 27: Dev loss: 0.055999168431043994, Record F1: 0.4162288363893871, Record EM: 0.3948497854077253, SQL EM: 0.006437768240343348\n",
            "Epoch 27: 20.17% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:49<00:00,  2.69it/s]\n",
            "Epoch 28: Average train loss was 0.060095066321788335\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:08<00:00, 12.56s/it]\n",
            "466it [01:58,  3.95it/s]\n",
            "Epoch 28: Dev loss: 0.04730471637951809, Record F1: 0.48302787724182084, Record EM: 0.4592274678111588, SQL EM: 0.015021459227467811\n",
            "Epoch 28: 10.52% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:48<00:00,  2.77it/s]\n",
            "Epoch 29: Average train loss was 0.049567309198060384\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:01<00:00, 12.10s/it]\n",
            "462it [02:00,  3.85it/s]\n",
            "Epoch 29: Dev loss: 0.04771665133653055, Record F1: 0.47330394947891113, Record EM: 0.44849785407725323, SQL EM: 0.015021459227467811\n",
            "Epoch 29: 14.81% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:49<00:00,  2.69it/s]\n",
            "Epoch 30: Average train loss was 0.04737547033773858\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [02:53<00:00, 11.57s/it]\n",
            "466it [00:43, 10.67it/s]\n",
            "Epoch 30: Dev loss: 0.060791387109141046, Record F1: 0.23232370598760133, Record EM: 0.1781115879828326, SQL EM: 0.012875536480686695\n",
            "Epoch 30: 14.59% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:49<00:00,  2.71it/s]\n",
            "Epoch 31: Average train loss was 0.05008870911400734\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:05<00:00, 12.36s/it]\n",
            "466it [01:39,  4.67it/s]\n",
            "Epoch 31: Dev loss: 0.04901248680600032, Record F1: 0.467670053969579, Record EM: 0.4248927038626609, SQL EM: 0.012875536480686695\n",
            "Epoch 31: 18.88% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:47<00:00,  2.80it/s]\n",
            "Epoch 32: Average train loss was 0.054012049985044656\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:13<00:00, 12.90s/it]\n",
            "438it [02:00,  3.65it/s]\n",
            "Epoch 32: Dev loss: 0.044119840789001816, Record F1: 0.4612200928254763, Record EM: 0.4313304721030043, SQL EM: 0.012875536480686695\n",
            "Epoch 32: 16.74% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:49<00:00,  2.67it/s]\n",
            "Epoch 33: Average train loss was 0.04412404211397384\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:13<00:00, 12.88s/it]\n",
            "463it [02:00,  3.86it/s]\n",
            "Epoch 33: Dev loss: 0.04634418038388307, Record F1: 0.44475497135481984, Record EM: 0.41201716738197425, SQL EM: 0.017167381974248927\n",
            "Epoch 33: 18.67% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:50<00:00,  2.65it/s]\n",
            "Epoch 34: Average train loss was 0.04207401514346387\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:22<00:00, 13.52s/it]\n",
            "459it [02:00,  3.82it/s]\n",
            "Epoch 34: Dev loss: 0.04092442394534315, Record F1: 0.48888462180555636, Record EM: 0.4613733905579399, SQL EM: 0.017167381974248927\n",
            "Epoch 34: 13.52% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:49<00:00,  2.71it/s]\n",
            "Epoch 35: Average train loss was 0.037709310090177625\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:47<00:00, 15.19s/it]\n",
            "454it [02:00,  3.78it/s]\n",
            "Epoch 35: Dev loss: 0.04047710405402684, Record F1: 0.5014944122171168, Record EM: 0.47639484978540775, SQL EM: 0.015021459227467811\n",
            "Epoch 35: 14.59% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:50<00:00,  2.62it/s]\n",
            "Epoch 36: Average train loss was 0.035398279158632584\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:38<00:00, 14.55s/it]\n",
            "465it [02:00,  3.87it/s]\n",
            "Epoch 36: Dev loss: 0.0405126476995189, Record F1: 0.5052216624695253, Record EM: 0.4742489270386266, SQL EM: 0.017167381974248927\n",
            "Epoch 36: 13.95% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:50<00:00,  2.62it/s]\n",
            "Epoch 37: Average train loss was 0.035737332219727955\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:48<00:00, 15.26s/it]\n",
            "464it [02:00,  3.87it/s]\n",
            "Epoch 37: Dev loss: 0.038674835259340526, Record F1: 0.47674565334753594, Record EM: 0.4678111587982833, SQL EM: 0.012875536480686695\n",
            "Epoch 37: 13.52% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:49<00:00,  2.66it/s]\n",
            "Epoch 38: Average train loss was 0.03185447122250851\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:51<00:00, 15.44s/it]\n",
            "396it [02:00,  3.30it/s]\n",
            "Epoch 38: Dev loss: 0.04253974721864287, Record F1: 0.45308670974509196, Record EM: 0.4184549356223176, SQL EM: 0.008583690987124463\n",
            "Epoch 38: 30.26% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:52<00:00,  2.53it/s]\n",
            "Epoch 39: Average train loss was 0.03718104641505363\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [04:07<00:00, 16.52s/it]\n",
            "463it [02:00,  3.86it/s]\n",
            "Epoch 39: Dev loss: 0.03910120733434858, Record F1: 0.5398566090584854, Record EM: 0.5214592274678111, SQL EM: 0.012875536480686695\n",
            "Epoch 39: 13.30% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:51<00:00,  2.59it/s]\n",
            "Epoch 40: Average train loss was 0.03611829807443809\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:32<00:00, 14.14s/it]\n",
            "465it [02:00,  3.87it/s]\n",
            "Epoch 40: Dev loss: 0.04684105682500891, Record F1: 0.4895886110913795, Record EM: 0.4656652360515021, SQL EM: 0.006437768240343348\n",
            "Epoch 40: 18.88% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:49<00:00,  2.68it/s]\n",
            "Epoch 41: Average train loss was 0.0358528261324676\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:36<00:00, 14.44s/it]\n",
            "465it [02:00,  3.87it/s]\n",
            "Epoch 41: Dev loss: 0.03757561899805256, Record F1: 0.5411704125601203, Record EM: 0.5150214592274678, SQL EM: 0.01072961373390558\n",
            "Epoch 41: 12.23% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:49<00:00,  2.69it/s]\n",
            "Epoch 42: Average train loss was 0.029549685825967717\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating: 100% 15/15 [03:34<00:00, 14.30s/it]\n",
            "457it [02:00,  3.81it/s]\n",
            "Epoch 42: Dev loss: 0.036242789084273995, Record F1: 0.5499516511424359, Record EM: 0.5214592274678111, SQL EM: 0.019313304721030045\n",
            "Epoch 42: 10.52% of the generated outputs led to SQL errors\n",
            "100% 133/133 [00:50<00:00,  2.61it/s]\n",
            "Epoch 43: Average train loss was 0.026452071003457426\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Evaluating:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Evaluating:  13% 2/15 [00:29<03:13, 14.90s/it]Exception ignored in: <generator object tqdm.__iter__ at 0x7c2ad249a5e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1197, in __iter__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1303, in close\n",
            "    self.display(pos=0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1496, in display\n",
            "    self.sp(self.__str__() if msg is None else msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1152, in __str__\n",
            "    return self.format_meter(**self.format_dict)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 618, in format_meter\n",
            "    l_bar += '{0:3.0f}%|'.format(percentage)\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/train_t5.py\", line 274, in <module>\n",
            "    main()\n",
            "  File \"/content/train_t5.py\", line 249, in main\n",
            "    train(args, model, train_loader, dev_loader, optimizer, scheduler)\n",
            "  File \"/content/train_t5.py\", line 72, in train\n",
            "    eval_loss, record_f1, record_em, sql_em, error_rate = eval_epoch(args, model, dev_loader,\n",
            "  File \"/content/train_t5.py\", line 177, in eval_epoch\n",
            "    outputs = model.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 1576, in generate\n",
            "    result = self._greedy_search(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 2494, in _greedy_search\n",
            "    outputs = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\", line 1742, in forward\n",
            "    decoder_outputs = self.decoder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\", line 1109, in forward\n",
            "    layer_outputs = layer_module(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\", line 689, in forward\n",
            "    self_attention_outputs = self.layer[0](\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\", line 596, in forward\n",
            "    attention_output = self.SelfAttention(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\", line 556, in forward\n",
            "    attn_weights = nn.functional.softmax(scores.float(), dim=-1).type_as(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 1856, in softmax\n",
            "    ret = input.softmax(dim)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Extra Credit: Scripts for generating all required outputs and analysis\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
        "from load_data import load_t5_data\n",
        "from utils import compute_metrics, save_queries_and_records\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "\n",
        "def generate_extra_credit_test_predictions():\n",
        "    \"\"\"Generate test predictions from the from-scratch model\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"GENERATING EXTRA CREDIT TEST PREDICTIONS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    checkpoint_path = 'checkpoints/scr_experiments/scr_experiment/best_model'\n",
        "\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        print(f\"⚠ ERROR: Model checkpoint not found at {checkpoint_path}\")\n",
        "        print(\"Please train the from-scratch model first:\")\n",
        "        print(\"  python train_t5.py [without --finetune flag]\")\n",
        "        return False\n",
        "\n",
        "    print(f\"\\nLoading model from {checkpoint_path}...\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(checkpoint_path)\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    print(\"✓ Model loaded\")\n",
        "\n",
        "    tokenizer = T5TokenizerFast.from_pretrained('google-t5/t5-small')\n",
        "\n",
        "    print(\"\\nLoading test data...\")\n",
        "    _, _, test_loader = load_t5_data(batch_size=16, test_batch_size=32)\n",
        "    print(\"✓ Data loaded\")\n",
        "\n",
        "    print(\"\\nGenerating predictions...\")\n",
        "    generated_queries = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encoder_input, encoder_mask, initial_decoder_input in tqdm(test_loader, desc=\"Test Inference\"):\n",
        "            encoder_input = encoder_input.to(DEVICE)\n",
        "            encoder_mask = encoder_mask.to(DEVICE)\n",
        "\n",
        "            outputs = model.generate(\n",
        "                input_ids=encoder_input,\n",
        "                attention_mask=encoder_mask,\n",
        "                max_length=512,\n",
        "                num_beams=4,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "            for output in outputs:\n",
        "                generated_sql = tokenizer.decode(output, skip_special_tokens=True)\n",
        "                generated_queries.append(generated_sql)\n",
        "\n",
        "    print(f\" Generated {len(generated_queries)} queries\")\n",
        "\n",
        "    output_sql = 'results/t5_ft_experiment_ec_test.sql'\n",
        "    output_pkl = 'records/t5_ft_experiment_ec_test.pkl'\n",
        "\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    os.makedirs('records', exist_ok=True)\n",
        "\n",
        "    print(f\"\\nSaving results...\")\n",
        "    save_queries_and_records(generated_queries, output_sql, output_pkl)\n",
        "    print(f\"Saved to {output_sql}\")\n",
        "    print(f\"Saved to {output_pkl}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EXTRA CREDIT TEST PREDICTIONS GENERATED!\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nFiles ready for submission:\")\n",
        "    print(f\"  - {output_sql}\")\n",
        "    print(f\"  - {output_pkl}\")\n",
        "    print(\"\\nSubmit these files to Gradescope Programming Assignment\")\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "def compare_models():\n",
        "    \"\"\"Compare fine-tuned and from-scratch models on dev set\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"COMPARING FINE-TUNED VS FROM-SCRATCH MODELS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    ft_sql = 'results/t5_ft_ft_experiment_dev.sql'\n",
        "    ft_pkl = 'records/t5_ft_ft_experiment_dev.pkl'\n",
        "\n",
        "    scr_sql = 'results/t5_scr_scr_experiment_dev.sql'\n",
        "    scr_pkl = 'records/t5_scr_scr_experiment_dev.pkl'\n",
        "\n",
        "    gt_sql = 'data/dev.sql'\n",
        "    gt_pkl = 'records/ground_truth_dev.pkl'\n",
        "\n",
        "    if not os.path.exists(ft_pkl):\n",
        "        print(f\"Fine-tuned results not found: {ft_pkl}\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(scr_pkl):\n",
        "        print(f\"From-scratch results not found: {scr_pkl}\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nFINE-TUNED MODEL:\")\n",
        "    print(\"-\" * 40)\n",
        "    ft_sql_em, ft_rec_em, ft_rec_f1, ft_errors = compute_metrics(gt_sql, ft_sql, gt_pkl, ft_pkl)\n",
        "    ft_error_rate = sum(1 for e in ft_errors if e != \"\") / len(ft_errors)\n",
        "\n",
        "    print(f\"SQL Exact Match: {ft_sql_em*100:.2f}%\")\n",
        "    print(f\"Record Exact Match: {ft_rec_em*100:.2f}%\")\n",
        "    print(f\"Record F1: {ft_rec_f1*100:.2f}%\")\n",
        "    print(f\"Error Rate: {ft_error_rate*100:.2f}%\")\n",
        "\n",
        "    print(\"\\nFROM-SCRATCH MODEL:\")\n",
        "    print(\"-\" * 40)\n",
        "    scr_sql_em, scr_rec_em, scr_rec_f1, scr_errors = compute_metrics(gt_sql, scr_sql, gt_pkl, scr_pkl)\n",
        "    scr_error_rate = sum(1 for e in scr_errors if e != \"\") / len(scr_errors)\n",
        "\n",
        "    print(f\"SQL Exact Match: {scr_sql_em*100:.2f}%\")\n",
        "    print(f\"Record Exact Match: {scr_rec_em*100:.2f}%\")\n",
        "    print(f\"Record F1: {scr_rec_f1*100:.2f}%\")\n",
        "    print(f\"Error Rate: {scr_error_rate*100:.2f}%\")\n",
        "\n",
        "    print(\"\\nCOMPARISON:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"SQL EM Difference: {(ft_sql_em - scr_sql_em)*100:+.2f} points\")\n",
        "    print(f\"Record EM Difference: {(ft_rec_em - scr_rec_em)*100:+.2f} points\")\n",
        "    print(f\"Record F1 Difference: {(ft_rec_f1 - scr_rec_f1)*100:+.2f} points\")\n",
        "    print(f\"Error Rate Difference: {(ft_error_rate - scr_error_rate)*100:+.2f} points\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"COMPARISON SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nFine-tuned model outperforms from-scratch by {(ft_rec_f1 - scr_rec_f1)*100:.2f} F1 points\")\n",
        "    print(f\"This demonstrates the value of pre-training for specialized tasks.\")\n",
        "\n",
        "\n",
        "\n",
        "def generate_extra_credit_latex():\n",
        "    \"\"\"Generate formatted values for extra credit LaTeX tables\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"EXTRA CREDIT LATEX VALUES\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    scr_sql = 'results/t5_scr_scr_experiment_dev.sql'\n",
        "    scr_pkl = 'records/t5_scr_scr_experiment_dev.pkl'\n",
        "    gt_sql = 'data/dev.sql'\n",
        "    gt_pkl = 'records/ground_truth_dev.pkl'\n",
        "\n",
        "    if not os.path.exists(scr_pkl):\n",
        "        print(\"From-scratch model not evaluated. Run evaluation first.\")\n",
        "        return\n",
        "\n",
        "    scr_sql_em, scr_rec_em, scr_rec_f1, scr_errors = compute_metrics(gt_sql, scr_sql, gt_pkl, scr_pkl)\n",
        "    scr_error_rate = sum(1 for e in scr_errors if e != \"\") / len(scr_errors)\n",
        "\n",
        "    print(\"\\nFor Table EC-3 (Results):\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Dev SQL EM: {scr_sql_em*100:.2f}\")\n",
        "    print(f\"Dev Record EM: {scr_rec_em*100:.2f}\")\n",
        "    print(f\"Dev Record F1: {scr_rec_f1*100:.2f}\")\n",
        "    print(f\"Error Rate: {scr_error_rate*100:.2f}%\")\n",
        "    print(\"\\nTest results: [Fill in after Gradescope submission]\")\n",
        "\n",
        "    ft_pkl = 'records/t5_ft_ft_experiment_dev.pkl'\n",
        "    if os.path.exists(ft_pkl):\n",
        "        ft_sql_em, ft_rec_em, ft_rec_f1, _ = compute_metrics(gt_sql, 'results/t5_ft_ft_experiment_dev.sql', gt_pkl, ft_pkl)\n",
        "\n",
        "        print(\"\\nFor Comparison Section:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"Fine-tuned F1: {ft_rec_f1*100:.2f}\")\n",
        "        print(f\"From-scratch F1: {scr_rec_f1*100:.2f}\")\n",
        "        print(f\"Difference: {(ft_rec_f1 - scr_rec_f1)*100:.2f} points\")\n",
        "\n",
        "\n",
        "\n",
        "def analyze_extra_credit_errors():\n",
        "    \"\"\"Analyze errors from the from-scratch model\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"EXTRA CREDIT ERROR ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    with open('data/dev.nl', 'r') as f:\n",
        "        nl_queries = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    with open('data/dev.sql', 'r') as f:\n",
        "        gt_sql = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    scr_sql_path = 'results/t5_scr_scr_experiment_dev.sql'\n",
        "    if not os.path.exists(scr_sql_path):\n",
        "        print(\"⚠ From-scratch predictions not found\")\n",
        "        return\n",
        "\n",
        "    with open(scr_sql_path, 'r') as f:\n",
        "        pred_sql = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    with open('records/t5_scr_scr_experiment_dev.pkl', 'rb') as f:\n",
        "        pred_records, error_msgs = pickle.load(f)\n",
        "\n",
        "    print(\"\\nFinding errors...\")\n",
        "    errors = []\n",
        "    for i, (nl, gt, pred, err) in enumerate(zip(nl_queries, gt_sql, pred_sql, error_msgs)):\n",
        "        if gt.lower() != pred.lower() or err != \"\":\n",
        "            errors.append({\n",
        "                'idx': i,\n",
        "                'nl': nl,\n",
        "                'gt': gt,\n",
        "                'pred': pred,\n",
        "                'error': err\n",
        "            })\n",
        "\n",
        "    print(f\"Found {len(errors)} errors out of {len(nl_queries)} queries\")\n",
        "    print(f\"Accuracy: {(len(nl_queries) - len(errors)) / len(nl_queries) * 100:.2f}%\")\n",
        "    print(\"\\nFirst 5 errors:\")\n",
        "    print(\"-\" * 80)\n",
        "    for i, err in enumerate(errors[:5], 1):\n",
        "        print(f\"\\nError {i} (Index {err['idx']}):\")\n",
        "        print(f\"  NL: {err['nl'][:80]}...\")\n",
        "        print(f\"  GT: {err['gt'][:80]}...\")\n",
        "        print(f\"  Pred: {err['pred'][:80]}...\")\n",
        "        if err['error']:\n",
        "            print(f\"  SQL Error: {err['error'][:50]}...\")\n",
        "\n",
        "    with open('extra_credit_errors.txt', 'w') as f:\n",
        "        f.write(\"EXTRA CREDIT ERROR ANALYSIS\\n\")\n",
        "        f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "        for err in errors:\n",
        "            f.write(f\"Index: {err['idx']}\\n\")\n",
        "            f.write(f\"NL: {err['nl']}\\n\")\n",
        "            f.write(f\"GT: {err['gt']}\\n\")\n",
        "            f.write(f\"Pred: {err['pred']}\\n\")\n",
        "            if err['error']:\n",
        "                f.write(f\"Error: {err['error']}\\n\")\n",
        "            f.write(\"\\n\" + \"-\"*80 + \"\\n\\n\")\n",
        "\n",
        "    print(f\"\\n✓ Detailed errors saved to: extra_credit_errors.txt\")\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main menu for extra credit scripts\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"*\"*80)\n",
        "    print(\"*\" + \" \"*78 + \"*\")\n",
        "    print(\"*\" + \" \"*20 + \"EXTRA CREDIT: MODEL ANALYSIS SCRIPTS\" + \" \"*23 + \"*\")\n",
        "    print(\"*\" + \" \"*78 + \"*\")\n",
        "    print(\"*\"*80 + \"\\n\")\n",
        "\n",
        "    print(\"Select an option:\")\n",
        "    print(\"  1. Generate test predictions for submission\")\n",
        "    print(\"  2. Compare fine-tuned vs from-scratch models\")\n",
        "    print(\"  3. Generate LaTeX table values\")\n",
        "    print(\"  4. Analyze errors\")\n",
        "    print(\"  5. Run all\")\n",
        "    print(\"  0. Exit\")\n",
        "\n",
        "    choice = input(\"\\nEnter choice (0-5): \").strip()\n",
        "\n",
        "    if choice == '1':\n",
        "        generate_extra_credit_test_predictions()\n",
        "    elif choice == '2':\n",
        "        compare_models()\n",
        "    elif choice == '3':\n",
        "        generate_extra_credit_latex()\n",
        "    elif choice == '4':\n",
        "        analyze_extra_credit_errors()\n",
        "    elif choice == '5':\n",
        "        print(\"\\nRunning all scripts...\\n\")\n",
        "        generate_extra_credit_test_predictions()\n",
        "        compare_models()\n",
        "        generate_extra_credit_latex()\n",
        "        analyze_extra_credit_errors()\n",
        "    elif choice == '0':\n",
        "        print(\"Exiting...\")\n",
        "        return\n",
        "    else:\n",
        "        print(\"Invalid choice!\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"*\"*80)\n",
        "    print(\"*\" + \" \"*78 + \"*\")\n",
        "    print(\"*\" + \" \"*30 + \"SCRIPT COMPLETE!\" + \" \"*33 + \"*\")\n",
        "    print(\"*\" + \" \"*78 + \"*\")\n",
        "    print(\"*\"*80 + \"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR55NKucQaxo",
        "outputId": "7348793c-59fe-4fe5-8144-eaa7568035bb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "*                                                                              *\n",
            "*                    EXTRA CREDIT: MODEL ANALYSIS SCRIPTS                       *\n",
            "*                                                                              *\n",
            "********************************************************************************\n",
            "\n",
            "Select an option:\n",
            "  1. Generate test predictions for submission\n",
            "  2. Compare fine-tuned vs from-scratch models\n",
            "  3. Generate LaTeX table values\n",
            "  4. Analyze errors\n",
            "  5. Run all\n",
            "  0. Exit\n",
            "\n",
            "Enter choice (0-5): 5\n",
            "\n",
            "Running all scripts...\n",
            "\n",
            "================================================================================\n",
            "GENERATING EXTRA CREDIT TEST PREDICTIONS\n",
            "================================================================================\n",
            "⚠ ERROR: Model checkpoint not found at checkpoints/scr_experiments/scr_experiment/best_model\n",
            "Please train the from-scratch model first:\n",
            "  python train_t5.py [without --finetune flag]\n",
            "================================================================================\n",
            "COMPARING FINE-TUNED VS FROM-SCRATCH MODELS\n",
            "================================================================================\n",
            "⚠ From-scratch results not found: records/t5_scr_scr_experiment_dev.pkl\n",
            "================================================================================\n",
            "EXTRA CREDIT LATEX VALUES\n",
            "================================================================================\n",
            "⚠ From-scratch model not evaluated. Run evaluation first.\n",
            "================================================================================\n",
            "EXTRA CREDIT ERROR ANALYSIS\n",
            "================================================================================\n",
            "⚠ From-scratch predictions not found\n",
            "\n",
            "********************************************************************************\n",
            "*                                                                              *\n",
            "*                              SCRIPT COMPLETE!                                 *\n",
            "*                                                                              *\n",
            "********************************************************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF2c-Ap7kDHE",
        "outputId": "1319aaf2-e122-4d98-e9b6-d67b87a6a123"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "backup_path = \"/content/drive/MyDrive/t5_backups\"\n",
        "os.makedirs(backup_path, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "mnOypsjcQDXe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import time\n",
        "\n",
        "src_records = \"/content/records\"\n",
        "src_results = \"/content/results\"\n",
        "\n",
        "dst_records = \"/content/drive/MyDrive/t5_backups/records\"\n",
        "dst_results = \"/content/drive/MyDrive/t5_backups/results\"\n",
        "\n",
        "shutil.copytree(src_records, dst_records, dirs_exist_ok=True)\n",
        "shutil.copytree(src_results, dst_results, dirs_exist_ok=True)\n",
        "\n",
        "print(\"Backup completed!\")\n",
        "\n",
        "time.sleep(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC0ELPwnQGNg",
        "outputId": "e5d06816-bb14-4bf1-e3d9-0258308cb70b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backup completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()\n"
      ],
      "metadata": {
        "id": "oFWEFWskQOkY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sUqT89FDQxAy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}